#!/usr/bin/env python3

"""
This program was generated by gpt-oss-20b. The prompt was the following.

--------
write a python program.
input is one csv file, which has many rows, 4 columns of float values.
First and second columns are input values, and third and fourth columns are output values.
write neural network prediction program to predict two output values.
Use torch and numpy packages.
--------



1. Loads a CSV file (`data.csv`) that contains *many* rows and exactly four columns of floats.  
2. Treats the first two columns as the input features `x` and the last two columns as the targets `y`.  
3. Builds a tiny fully‑connected neural network with PyTorch, trains it on the data,
     and finally prints out predictions for all samples (you can also test it on a held‑out split).  

Feel free to tweak the hyper‑parameters (layers, learning rate, epochs…) to suit your dataset.

Simple 2‑output regression network using PyTorch.
Input CSV format:   col0 , col1 , col2 , col3
                     ^     ^      ^      ^
                   x[0]  x[1]   y[0]   y[1]

                   
                   
### How to use

# 1. Make sure you have the required packages installed
pip install numpy torch

# 2. Run the script on your CSV file
python train_regressor.py data.csv --output my_predictions.csv

The script will:

* Read `data.csv`.
* Train a small fully‑connected neural network for **200 epochs** (default).  
  * You can change the number of epochs, learning rate, hidden size, etc. via command‑line arguments.
* Save the best model (`best_model.pt`).
* Predict the two output values for every row in the input file and write them to `my_predictions.csv`.

Feel free to adapt the architecture (e.g., add more layers, change activations)
or replace the MSE loss with something else if your task requires it.                   

"""

import argparse
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim


# --------------------------------------------------------------------------- #
# 1. Data loading helpers
# --------------------------------------------------------------------------- #
def load_csv(path: str | Path) -> tuple[np.ndarray, np.ndarray]:
    """
    Load the CSV file and return (X, Y).

    X : shape (N, 2)
    Y : shape (N, 2)
    """
    data = np.loadtxt(str(path), delimiter=",")
    if data.shape[1] != 4:
        raise ValueError("CSV must contain exactly four columns.")
    X = data[:, :2].astype(np.float32)   # first two columns
    Y = data[:, 2:].astype(np.float32)   # last two columns
    return X, Y


def train_val_split(X: np.ndarray,
                    Y: np.ndarray,
                    val_ratio: float = 0.1,
                    seed: int | None = None):
    """
    Randomly split the dataset into training and validation sets.
    """
    rng = np.random.default_rng(seed)
    n_samples = X.shape[0]
    idx = rng.permutation(n_samples)

    n_val = int(np.floor(val_ratio * n_samples))
    val_idx, train_idx = idx[:n_val], idx[n_val:]

    return X[train_idx], Y[train_idx], X[val_idx], Y[val_idx]


# --------------------------------------------------------------------------- #
# 2. Model definition
# --------------------------------------------------------------------------- #
class SimpleRegressor(nn.Module):
    def __init__(self, hidden_dim: int = 64):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 2),   # two outputs
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)


# --------------------------------------------------------------------------- #
# 3. Training routine
# --------------------------------------------------------------------------- #
def train_one_epoch(model,
                    dataloader,
                    criterion,
                    optimizer):
    model.train()
    epoch_loss = 0.0
    for xb, yb in dataloader:
        optimizer.zero_grad()
        preds = model(xb)
        loss = criterion(preds, yb)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item() * xb.size(0)
    return epoch_loss / len(dataloader.dataset)


def evaluate(model,
             dataloader,
             criterion):
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for xb, yb in dataloader:
            preds = model(xb)
            loss = criterion(preds, yb)
            val_loss += loss.item() * xb.size(0)
    return val_loss / len(dataloader.dataset)


# --------------------------------------------------------------------------- #
# 4. Main script
# --------------------------------------------------------------------------- #
def main(args):
    # Load data
    X, Y = load_csv(args.input)

    # Split into train/val (80/20 by default)
    X_train, Y_train, X_val, Y_val = train_val_split(
        X, Y, val_ratio=args.val_ratio, seed=args.seed
    )

    # Convert to torch tensors
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    train_dataset = torch.utils.data.TensorDataset(
        torch.from_numpy(X_train), torch.from_numpy(Y_train)
    )
    val_dataset = torch.utils.data.TensorDataset(
        torch.from_numpy(X_val), torch.from_numpy(Y_val)
    )

    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True
    )
    val_loader = torch.utils.data.DataLoader(
        val_dataset, batch_size=args.batch_size, shuffle=False
    )

    # Build model, criterion and optimizer
    model = SimpleRegressor(hidden_dim=args.hidden).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=args.lr)

    # Training loop
    best_val_loss = float("inf")
    for epoch in range(1, args.epochs + 1):
        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)
        val_loss = evaluate(model, val_loader, criterion)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), "best_model.pt")

        print(
            f"Epoch {epoch:03d} | "
            f"train loss={train_loss:.6f} | "
            f"val   loss={val_loss:.6f}"
        )

    # Load best model and predict on the whole dataset
    model.load_state_dict(torch.load("best_model.pt"))
    all_tensor = torch.from_numpy(X).to(device)
    with torch.no_grad():
        preds = model(all_tensor).cpu().numpy()

    # Save predictions (optional)
    np.savetxt(args.output, preds, delimiter=",", fmt="%.2f")
    print(f"Predictions written to {args.output}")

    # XXX Added by a human
    pred_center_low = preds[:, 0]
    pred_center_high = preds[:, 1]
    mean_center_low = np.mean(pred_center_low)
    mean_center_high = np.mean(pred_center_high)
    mean_ratio = mean_center_high / mean_center_low
    print(f"Mean of predicted center intensity for LOW images: {mean_center_low:.0f}")
    print(f"Mean of predicted center intensity for HIGH images: {mean_center_high:.0f}")
    print(f"Mean ratio of HIGH/LOW center intensity: {mean_ratio:.4f}")
    # XXX end of human edit

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Train a 2‑output regression network on a CSV file."
    )
    parser.add_argument("input", type=str, help="Path to input CSV file.")
    parser.add_argument("--output",
                        type=str,
                        default="predictions.csv",
                        help="Where to store predictions.")
    parser.add_argument(
        "--epochs",
        type=int,
        default=200,
        help="Number of training epochs.",
    )
    parser.add_argument(
        "--batch_size", type=int, default=128, help="Training batch size."
    )
    parser.add_argument(
        "--lr", type=float, default=1e-3, help="Learning rate."
    )
    parser.add_argument(
        "--hidden",
        type=int,
        default=64,
        help="Size of the hidden layer.",
    )
    parser.add_argument(
        "--val_ratio",
        type=float,
        default=0.2,
        help="Fraction of data to reserve for validation.",
    )
    parser.add_argument("--seed", type=int, default=None, help="Random seed.")
    args = parser.parse_args()
    main(args)
